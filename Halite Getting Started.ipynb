{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install kaggle-environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# 1. Enable Internet in the Kernel (Settings side pane)\n",
    "\n",
    "# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n",
    "# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n",
    "\n",
    "# Halite environment was defined in v0.2.1\n",
    "# !pip install kaggle-environments>=0.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Halite Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from kaggle_environments import evaluate, make\n",
    "\n",
    "env = make(\"halite\", debug=True)\n",
    "env.render(mode=\"ipython\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Submission (agent)\n",
    "\n",
    "To submit to the competition, a python file must be created where the last function is the \"act\" (the function which given an observation generates an action).  Logic above the \"act\" function is allowed including helpers.  Any python that executes immediately will be run during the initialize phase and not included in the \"act timeout\".\n",
    "\n",
    "When your agent is being evaluated against others, it will not have access to the Kaggle docker image. Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# agent file to test:\n",
    "agent_file = \"/kaggle/working/base.py\"\n",
    "agent_file = \"base.py\"\n",
    "opp_file = \"old_base.py\"\n",
    "\n",
    "# Play against yourself without an ERROR or INVALID.\n",
    "# Note: The first episode in the competition will run this to weed out erroneous agents.\n",
    "#env.run([agent_file, agent_file])\n",
    "#print(\"EXCELLENT SUBMISSION!\" if env.toJSON()[\"statuses\"] == [\"DONE\", \"DONE\"] else \"MAYBE BAD SUBMISSION?\")\n",
    "\n",
    "# Play as the first agent against default \"shortest\" agent.\n",
    "def null_agent(obs):\n",
    "    #if(obs.step==0):\n",
    "    #    print(obs)\n",
    "    #if(obs.step <= 10):\n",
    "    #    print('STEP: ', obs.step)\n",
    "    #    print(\"EMPTY in fron: \",obs.halite[204])\n",
    "    #    print(\"OCCUPIED: \",obs.halite[225])\n",
    "    #    print('My Halite: ',obs.players[1][2]['0-2'][1])\n",
    "    return {}\n",
    "\n",
    "env.run([agent_file, null_agent])\n",
    "env.render(mode=\"ipython\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_file = \"map_analysis.py\"\n",
    "\n",
    "# Play against yourself without an ERROR or INVALID.\n",
    "# Note: The first episode in the competition will run this to weed out erroneous agents.\n",
    "#env.run([agent_file, agent_file])\n",
    "#print(\"EXCELLENT SUBMISSION!\" if env.toJSON()[\"statuses\"] == [\"DONE\", \"DONE\"] else \"MAYBE BAD SUBMISSION?\")\n",
    "\n",
    "# Play as the first agent against default \"shortest\" agent.\n",
    "def null_agent(*_): return {}\n",
    "env.run([agent_file, null_agent])\n",
    "env.render(mode=\"ipython\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def null_agent(*_): return {}\n",
    "for _ in range(1):\n",
    "    env = make(\"halite\", debug=True)\n",
    "    env.run([agent_file, null_agent])\n",
    "    env.render(mode=\"ipython\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug/Train your Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Play as first position against random agent.\n",
    "trainer = env.train([None, \"random\"])\n",
    "\n",
    "observation = trainer.reset()\n",
    "\n",
    "from base import agent\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Play as first position against random agent.\n",
    "def null_agent(obs):\n",
    "    return {}\n",
    "\n",
    "def discrete_cmap(N, base_cmap=None):  #https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n",
    "\n",
    "\n",
    "trainer = env.train([None, \"random\"])\n",
    "\n",
    "observation = trainer.reset()\n",
    "import importlib\n",
    "#import map_analysis\n",
    "import base\n",
    "importlib.reload(base)\n",
    "#importlib.reload(map_analysis)\n",
    "count = 0\n",
    "#checks = [10, 75, 150, 300, 398]\n",
    "#thresh = [80, 200, 250, 325, 325]\n",
    "checks = [3]\n",
    "#thresh = [200]\n",
    "fignum = 1\n",
    "while not env.done:\n",
    "    my_action,board,cluster_board, cluster_centers = base.agent(observation)\n",
    "    #print(\"My Action\", my_action)\n",
    "    observation, reward, done, info = trainer.step(my_action)\n",
    "    #print(reward)\n",
    "    #print(done)\n",
    "    #print(info)\n",
    "    if(count in checks):\n",
    "        \"\"\"\n",
    "        b[b < 0] = 0\n",
    "        plt.figure(fignum)\n",
    "        fignum+=1\n",
    "        plt.title(\"Map: \"+str(count))\n",
    "        plt.imshow(b)\n",
    "        plt.colorbar()\n",
    "        plt.figure(fignum)\n",
    "        fignum+=1\n",
    "        plt.title(\"Blur: \"+str(count))\n",
    "        g = scipy.ndimage.filters.gaussian_filter(b,1.0)\n",
    "        plt.imshow(g)\n",
    "        plt.colorbar()\n",
    "        plt.figure(fignum)\n",
    "        fignum+=1\n",
    "        plt.title(\"Blur with Threshold: \"+str(count))\n",
    "        print(checks.index(count))\n",
    "        plt.imshow(g>thresh[checks.index(count)])\n",
    "        \n",
    "        plt.figure(fignum)\n",
    "        fignum+=1\n",
    "        plt.title(\"Map: \"+str(count))\n",
    "        plt.imshow(b)\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.figure(fignum)\n",
    "        fignum+=1\n",
    "        plt.title(\"Concat Map: \"+str(count))\n",
    "        plt.imshow(b_concat)\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.figure(fignum)\n",
    "        fignum+=1\n",
    "        plt.title(\"Wrapped Map: \"+str(count))\n",
    "        plt.imshow(b_wrap)\n",
    "        plt.colorbar()\n",
    "        \"\"\"\n",
    "        plt.figure(fignum)\n",
    "        fignum+=1\n",
    "        plt.title(\"Map: \"+str(count))\n",
    "        plt.imshow(board)\n",
    "        plt.colorbar()\n",
    "\n",
    "\n",
    "        plt.figure(fignum)\n",
    "        fignum+=1\n",
    "        plt.title(\"Cluster: \"+str(count))\n",
    "        plt.imshow(cluster_board,cmap=discrete_cmap(len(cluster_centers), 'cubehelix'))\n",
    "        plt.colorbar(ticks=range(len(cluster_centers)))\n",
    "        plt.clim(-0.5, len(cluster_centers) - 0.5)\n",
    "        #plt.colorbar()\n",
    "        #print(d)\n",
    "        #print(c)\n",
    "        \n",
    "    count+=1\n",
    "#env.render(mode=\"ipython\", width=100, height=90)\n",
    "print(\"DEBUG COUNT: \", count)\n",
    "env.render(mode=\"ipython\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reward(rewards):\n",
    "    wins = 0\n",
    "    ties = 0\n",
    "    loses = 0\n",
    "    for r in rewards:\n",
    "        r0 = 0 if r[0] is None else r[0]\n",
    "        r1 = 0 if r[1] is None else r[1]\n",
    "        if r0 > r1:\n",
    "            wins += 1\n",
    "        elif r1 > r0:\n",
    "            loses += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "    return f'wins={wins/len(rewards)}, ties={ties/len(rewards)}, loses={loses/len(rewards)}'\n",
    "\n",
    "# Run multiple episodes to estimate its performance.\n",
    "# Setup agentExec as LOCAL to run in memory (runs faster) without process isolation.\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\n",
    "    \"halite\",\n",
    "    [\"/kaggle/working/\"+agent_file, \"random\"],\n",
    "    num_episodes=10, configuration={\"agentExec\": \"LOCAL\"}\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Competition\n",
    "\n",
    "1. Commit this kernel.\n",
    "2. View the commited version.\n",
    "3. Go to \"Data\" section and find submission.py file.\n",
    "4. Click \"Submit to Competition\"\n",
    "5. Go to [My Submissions](https://kaggle.com/c/halite/submissions) to view your score and episodes being played."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bita3e66381dd0344ef860197ad8d2de754"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}